#define BLOCK_SIZE 10
 # include <cuda.h>
 # include <iostream>
 using namespace std;
 
 void print_array(int *arr, int size){
 for (int i=0;i<size;i++){
 
 cout<< arr[i] << " ";
 }
 cout<< endl;
 }
 
 __global__ void add(int *arr1, int * arr2, int * result, int size){
 
 int block_id = blockIdx.x * blockDim.x + threadIdx.x;
 if (block_id < size){
 result[block_id] = arr1[block_id] + arr2[block_id];
 }
 }
 
 int main(){
 
 //initialize
 int size = 10;
 int arr1_cpu[size] = {1,2,3,4,5,6,7,8,9,10};
 int arr2_cpu[size] = {10,9,8,7,6,5,4,3,2,1};
 int result_cpu[size];
 
 int *arr1_gpu, *arr2_gpu, *result_gpu;
 
 //allocate memory to gpu
 cudaMalloc(&arr1_gpu, size*sizeof(int));
 cudaMalloc(&arr2_gpu, size*sizeof(int));
 cudaMalloc(&result_gpu,size*sizeof(int));
 
 //copy data from cpu to gpu
 cudaMemcpy(arr1_gpu,arr1_cpu,size*sizeof(int),cudaMemcpyHostToDevice);
 cudaMemcpy(arr2_gpu,arr2_cpu,size*sizeof(int),cudaMemcpyHostToDevice);
 
 // Configuration for Execution
 dim3 dimGrid((size+BLOCK_SIZE-1)/BLOCK_SIZE);
 dim3 dimBlock(BLOCK_SIZE);
 
 //Launch Kernel
 add<<<dimGrid,dimBlock>>>(arr1_gpu,arr2_gpu,result_gpu,size);
 
 // copy data from gpu to cpu
 cudaMemcpy(result_cpu,result_gpu,size*sizeof(int),cudaMemcpyDeviceToHost);
 
 cout<<"GPU Result: \n";
 print_array(result_cpu,size);
 
 
 }

nvcc -o add_vectors add_vectors.cu

./add_vectors
